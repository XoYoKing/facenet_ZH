# 变分自编码器

该页面描述如何去：

1、基于facenet感知损失训练变分自编码器，论文见“[Deep Feature Consistent Variational Autoencoder](https://arxiv.org/abs/1610.00291) ”。

2、计算基于CelebA数据集属性的属性向量。

3、通过将属性向量添加到图像的潜在变量中，向脸添加笑脸。来自CelebA数据集的潜在变量用来产生未修改的人脸图像。

在开始之前假设你已经：

 * 克隆项目资源
 * 设置python路径
 * 对齐数据集
 * 从[20170512-110547](https://drive.google.com/file/d/0B5MzpY9kBtDVZ2RpVDYwWmxoSUk) 下载并打出感知模型。

# 训练变分自编码器

本节介绍了如何使用知觉损失训练变自编码（VAE）,而不是依赖于训练图像和重建图像之间的像素差异的损失，知觉损失试图生成一个具有类似的空间特征的图像作为源图像。

为了实现这一点，在预训练的人脸识别模型中训练一些中间层激活的L2差异。确切地说，哪些层用于这一点并没有被认真调查，因此在这方面可能还有改进的余地。但是，在感知模型中不同层次训练的两种模型的性能比较是不容易的，因此必须手动检查结果。可以通过在感知模型中使用更高层的方法避免产生奇怪人脸的错误案例。

此外，重建损失和Kullback Leibler发散损失的因素通过调查或优化能取得一些好处。